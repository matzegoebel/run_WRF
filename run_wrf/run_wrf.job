#!/bin/bash

start_time=$(date +%s)

set -e


if (( cluster == 1 ))
then
  cluster=true
  module purge
  eval $module_load

else
  cluster=false
fi

ulimit -s unlimited

code_dir=$(pwd)

echo "jobs: $jobs"
jobs=(${jobs})
njobs=${#jobs[@]}
nslots=(${nslots})
nx=(${nx})
ny=(${ny})
runlog=run_${timestamp}.log
runerr=run_${timestamp}.err


si=0
pool=false
if (( $njobs > 1 )) && (( pool_jobs == 1 )) && (( batch == 1 )) && [[ $job_scheduler == "sge" ]]
then
  pool=true
  qs=$(qstat -t)
  hosts=$(python ${code_dir}/pool/get_hosts.py "$JOB_ID" "$qs")
  hosts=(${hosts})
  echo "hosts ${hosts[*]}"
fi


pid=()
set +e
trap 'rc=$?' ERR

for (( i=0; i<$njobs; i++ ))
do
  cd ${run_path}/WRF_${jobs[i]}
  #include information about number of processors in namelist.input
  source ${code_dir}/search_replace.sh namelist.input namelist.input 0 nproc_x ${nx[i]} nproc_y ${ny[i]}

  exec 1> $runlog
  exec 2> $runerr
  echo
  echo
  echo "Running job: ${jobs[i]}"
  nsi=${nslots[i]}
  echo "slots: $nsi "
  if (( nsi > 1 ))
  then
    echo "parallel"
    if $pool
    then
      echo "si $si"
      hostsi=${hosts[@]:$si:$nsi}
      echo "on hosts: $hostsi"

      H=$(python ${code_dir}/pool/get_hosts_set.py "$hostsi")
      python ${code_dir}/pool/rankfile.py  "${hosts[*]}" "$si" "$nsi" > rankfile.$JOB_ID
      cat rankfile.$JOB_ID

      mpiexec -H $H -rf rankfile.$JOB_ID -mca rmaps_rank_file_physical 1 -np $nsi -v -report-bindings -display-map -display-allocation ./wrf.exe & pid[i]=$!
      si=$((si + nsi))
      #~ sleep 20
    else
      mpiexec -np $nsi -v ./wrf.exe  & pid[i]=$!
      echo "mpiexec -np $nsi -v ./wrf.exe  & pid[i]=$!"
    fi
  else
    echo "serial run"
    ./wrf.exe & pid[i]=$!
  fi
  echo
  echo
done

sleep 1
#~ top -u $USER -bn 1 >> ../pidlog

finished=() #finished jobs

elapsed_t=0
enforce_rtlimit=true
if [[ -z ${rtlimit} ]]
then
  enforce_rtlimit=false
  rtlimit=1
fi

#wait until processes are finished or hard time limit almost reached
while [[ ${#finished[@]} -lt $njobs ]] && [[ ${elapsed_t} -le ${rtlimit} ]]
do

  elapsed_t=$(($(date +%s) - start_time))
  
  for (( i=0; i<$njobs; i++ ))
  do
    cd ${run_path}/WRF_${jobs[i]}
    exec 1>> $runlog
    exec 2>> $runerr
    #check if process is finished and append job to finished array if it is not yet in it
    if [[ -z $(ps -o pid= -p ${pid[i]}) ]] && [[ ! " ${finished[@]} " =~ " ${i} " ]]
    then
      sleep 1
      echo  "Job WRF_${jobs[i]} finished. Elapsed time (s): ${elapsed_t}"
      finished+=($i)
    fi
  done
  if ! ${enforce_rtlimit}
  then
    elapsed_t=0
  fi
  sleep 1
done
    
#clean up
for (( i=0; i<$njobs; i++ ))
do
  cd ${run_path}/WRF_${jobs[i]}
  exec 1>> $runlog
  exec 2>> $runerr

  echo
  echo

  if [[ -f rsl.error.0000 ]]
  then
    cat rsl.error.0000
  fi

  echo
  
  if [[ ! " ${finished[@]} " =~ " ${i} " ]]
  then
    echo "The job is about to terminate soon! Killing wrf.exe processes..."
    kill ${pid[i]} &
  fi

  echo "job ${jobs[i]} exited with code $?"

  if (( batch == 1 ))
  then
    #save resource usage of job
    if [[ $job_scheduler == "sge" ]]
    then
      qstat -j $JOB_ID > resources_${timestamp}.info
    elif [[ $job_scheduler == "slurm" ]]
    then
      sacct -j $SLURM_JOB_ID -l -p > resources_${timestamp}.info
    fi
    #prepend log to run log
    echo -e "$(cat ${qlog}.out)\n$(cat $runlog)" > $runlog
    echo -e "$(cat ${qlog}.err)\n$(cat $runerr)" > $runerr
  fi

  cat $runlog > run.log
  cat $runerr > run.err
done

for (( i=0; i<$njobs; i++ ))
do
  cd ${run_path}/WRF_${jobs[i]}
  exec 1>> $runlog
  exec 2>> $runerr

  echo
  elapsed_t=$(($(date +%s) - start_time))
  echo  "Job finished, total elapsed time (s): ${elapsed_t}"
done

#echo "trap" $rc
exit ${rc}
