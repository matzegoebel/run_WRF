#!/bin/bash

start_time=$(date +%s)

set -e


if (( cluster == 1 ))
then
  cluster=true
  eval $module_load

else
  cluster=false
fi

ulimit -s unlimited

code_dir=$(pwd)

echo "jobs: $jobs"
jobs=(${jobs})
njobs=${#jobs[@]}
nslots=(${nslots})
wrfv=(${wrfv})


si=0
pool=false
echo "JOBID ${SLURM_JOB_ID}"
if (( $njobs > 1 )) && (( pool_jobs == 1 )) && (( batch == 1 )) && [[ $job_scheduler == "sge" ]]
then
  pool=true
  qs=$(qstat -t)
  hosts=$(python ${code_dir}/pool/get_hosts.py "$JOB_ID" "$qs")
  hosts=(${hosts})
  echo "hosts ${hosts[*]}"
fi


pid=()
set +e
trap 'rc=$?' ERR

for (( i=0; i<$njobs; i++ ))
do
  cd ${run_path}/WRF_${jobs[i]}

  #redirect logs to file
  if (( restart == 1 ))
  then
    exec 1>> "run.log"
  else
    exec 1> "run.log"
  fi

  exec 2> "run.err"
  echo
  echo
  echo "Running job: ${jobs[i]}"
  nsi=${nslots[i]}
  wrf_dir_i=${wrfv[i]}
  echo "slots: $nsi "

  if (( nsi > 1 ))
  then
    echo "parallel"
    if $pool
    then
      echo "si $si"
      hostsi=${hosts[@]:$si:$nsi}
      echo "on hosts: $hostsi"

      H=$(python ${code_dir}/pool/get_hosts_set.py "$hostsi")
      python ${code_dir}/pool/rankfile.py  "${hosts[*]}" "$si" "$nsi" > rankfile.$JOB_ID
      cat rankfile.$JOB_ID

      mpiexec -H $H -rf rankfile.$JOB_ID -mca rmaps_rank_file_physical 1 -np $nsi -v -report-bindings -display-map -display-allocation ./wrf.exe & pid[i]=$!
      si=$((si + nsi))
      sleep 20
    else
      mpiexec -np $nsi -v ./wrf.exe  & pid[i]=$!
      echo "mpiexec -np $nsi -v ./wrf.exe  & pid[i]=$!"
    fi
  else
    echo "serial run"
    ./wrf.exe & pid[i]=$!
  fi
  echo
  echo
done
currtime=$(date +%d-%m-%Y_%H:%M:%S)

if [[ ${rtlimit} ]]
then
  elapsed_t=$(($(date +%s) - start_time))
else
  elapsed_t=0
  rtlimit=1
fi

finished=() #finished jobs
#write vmem usage to file until processes are finished or hard time limit almost reached
while [[ ${#finished[@]} -lt $njobs ]] && [[ ${elapsed_t} -le ${rtlimit} ]]
do
  for (( i=0; i<$njobs; i++ ))
  do
    cd ${run_path}/WRF_${jobs[i]}
    exec 1>> "run.log"
    exec 2>> "run.err"
    if [[ $(ps -o pid= -p ${pid[i]}) ]] #check if process is running
    then
      sleep 1
       # echo  "Elapsed time (s): $(($(date +%s) - start_time))"
      children=$(pgrep -P ${pid[i]} -d " ")
      children_l=($children)
      if [[ ${#children_l[@]} == 1 ]]
      then
        children="$children $(pgrep -P $children -d " ")"
      fi
      all_pids_arr="${pid[i]} $children"
      all_pids_arr=(${all_pids_arr})
      all_pids=$(IFS=, ; echo "${all_pids_arr[*]}")
      echo "${jobs[i]} $all_pids" >> ../pidlog
      top -bn 1 -p $all_pids | tail -n ${#all_pids_arr[@]}  | awk '{ printf("%-8s\n", $6) };' | paste -sd+ | bc >> vmemusage_$currtime
    elif [[ ! " ${finished[@]} " =~ " ${i} " ]] #append job to finished array if it is not yet in it
    then
      finished+=($i)
     # echo "finished ${finished[@]}"
    fi
  done
done
    

#clean up
for (( i=0; i<$njobs; i++ ))
do
  if (( ${nslots[i]} > 1 ))
  then
    cat rsl.error.0000 >> run.log
  fi

  if [[ ! " ${finished[@]} " =~ " ${i} " ]]
  then
    echo "The job is about to terminate soon! Killing wrf.exe processes..."
    kill ${pid[i]} &
  fi

  echo "job ${jobs[i]} exited with code $?"

  if (( batch == 1 ))
  then
    #save resource usage of job
    if [[ $job_scheduler == "sge" ]]
    then
      qstat -j $JOB_ID > resources_${currtime}.info
    elif [[ $job_scheduler == "slurm" ]]
    then
      sacct -j $SLURM_JOB_ID -l -p > resources_${currtime}.info
    fi
    #prepend log to run log
    echo -e "$(cat ${run_path}/logs/$JOB_NAME.out)\n$(cat run.log)" > run.log
    echo -e "$(cat ${run_path}/logs/$JOB_NAME.err)\n$(cat run.err)" > run.err
  fi

  if (( restart == 1 ))
  then
      cd ${run_path}/WRF_${jobs[i]}
      exec 1>> "run.log"
      exec 2>> "run.err"
      echo
      echo "Concatenate output from original and restarted run"
      python -c "import misc_tools; misc_tools.concat_restart('$outpath', '${jobs[i]}')"
  fi
done

#echo "trap" $rc
exit ${rc}
