#!/bin/bash

#$ -q std.q
#$ -cwd
#$ -N wrf_test
#$ -o /scratch/$USER/phd/logs/$JOB_NAME_$JOB_ID.out
#$ -e /scratch/$USER/phd/logs/$JOB_NAME_$JOB_ID.err

# -j yes
#$ -l h_rt=00:20:00
#$ -M matthias.goebel@uibk.ac.at
#$ -m sea
#$ -l h_vmem=1500M

set -e

if [ -z $ENVIRONMENT ]
then
  home_dir="$HOME"
  cluster=false

else
  home_dir="$SCRATCH"
  cluster=true
  echo "start cluster job"
  if [ -d ${homedir}/parallel_studio_2019 ]
  then
    module purge
    export NETCDF="${home_dir}/netcdf"
    source ${home_dir}/parallel_studio_2019/parallel_studio_xe_2019.4.070/bin/psxevars.sh
  else
    module load intel/18.0u1 netcdf-4
  fi
fi

ulimit -s unlimited

echo "jobs: $jobs"
jobs=(${jobs})
nslots=(${nslots})
wrfv=(${wrfv})

echo "job ID : $JOB_ID"
echo

 
si=0
pool=false
if (( ${#jobs[@]} > 1 ))
then
  if [ $use_rankfiles == "True" ]
  then
    pool=true
    qs=$(qstat -t)
    hosts=$(python ${home_dir}/phd/code/wrf_related/get_hosts.py "$JOB_ID" "$qs")
    hosts=(${hosts})
    echo "hosts ${hosts[*]}"
  fi
fi

for (( i=0; i<${#jobs[@]}; i++ ))
do
  cd ${home_dir}/wrf/runs/WRF_${jobs[$i]}
  echo "Running job: ${jobs[$i]}"
  nsi=${nslots[$i]}
  wrf_dir_i=${wrfv[$i]}
  echo "slots: $nsi "

  if [[ ${wrf_dir_i} == *"par"* ]]
  then
    echo "parallel"
    if $pool
    then
      echo "si $si"
      hostsi=${hosts[@]:$si:$nsi}
      echo "on hosts: $hostsi"

      H=$(python ${home_dir}/phd/code/wrf_related/get_hosts_set.py "$hostsi")
      python ${home_dir}/phd/code/wrf_related/rankfile.py  "${hosts[*]}" "$si" "$nsi" > rankfile.$JOB_ID
      cat rankfile.$JOB_ID

      mpiexec -H $H -rf rankfile.$JOB_ID -mca rmaps_rank_file_physical 1 -np $nsi -v -report-bindings -display-map -display-allocation ./wrf.exe  > run.log 2> run.err || true &
      si=$((si + nsi))
      sleep 20

    else
      mpiexec -np $nsi -v ./wrf.exe  > run.log 2> run.err || true  &
    fi
  else
    echo "serial run"
    ./wrf.exe > run.log 2> run.err &
    

  fi
  echo 
  echo
done

if $cluster
then
  wait
fi
