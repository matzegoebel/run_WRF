#!/bin/bash

start_time=$(date +%s)

set -e


if (( cluster == 1 ))
then
  cluster=true
  eval $module_load

else
  cluster=false
fi

ulimit -s unlimited

code_dir=$(pwd)

echo "jobs: $jobs"
jobs=(${jobs})
nslots=(${nslots})
wrfv=(${wrfv})


si=0
pool=false
echo "JOBID ${SLURM_JOB_ID}"
if (( ${#jobs[@]} > 1 )) && (( pool_jobs == 1 )) && (( batch == 1 )) && [[ $job_scheduler == "sge" ]]
then
  pool=true
  qs=$(qstat -t)
  hosts=$(python ${code_dir}/pool/get_hosts.py "$JOB_ID" "$qs")
  hosts=(${hosts})
  echo "hosts ${hosts[*]}"
fi


pid=()
set +e
trap 'rc=$?' ERR

for (( i=0; i<${#jobs[@]}; i++ ))
do
  cd ${run_path}/WRF_${jobs[i]}

  #redirect logs to file
  if (( restart == 1 ))
  then
    exec 1>> "run.log"
  else
    exec 1> "run.log"
  fi

  exec 2> "run.err"
  echo
  echo
  echo "Running job: ${jobs[i]}"
  nsi=${nslots[i]}
  wrf_dir_i=${wrfv[i]}
  echo "slots: $nsi "

  if (( nsi > 1 ))
  then
    echo "parallel"
    if $pool
    then
      echo "si $si"
      hostsi=${hosts[@]:$si:$nsi}
      echo "on hosts: $hostsi"

      H=$(python ${code_dir}/pool/get_hosts_set.py "$hostsi")
      python ${code_dir}/pool/rankfile.py  "${hosts[*]}" "$si" "$nsi" > rankfile.$JOB_ID
      cat rankfile.$JOB_ID

      mpiexec -H $H -rf rankfile.$JOB_ID -mca rmaps_rank_file_physical 1 -np $nsi -v -report-bindings -display-map -display-allocation ./wrf.exe & pid[i]=$!
      si=$((si + nsi))
      sleep 20
    else
      mpiexec -np $nsi -v ./wrf.exe  & pid[i]=$!
      echo "mpiexec -np $nsi -v ./wrf.exe  & pid[i]=$!"
    fi
  else
    echo "serial run"
    ./wrf.exe & pid[i]=$!
  fi
  echo
  echo
done
echo "runtime limit: ${rtlimit}"
currtime=$(date +%d-%m-%Y_%H:%M:%S)
while [[ $(($(date +%s) - start_time)) -le ${rtlimit} ]]
do
 # echo  "Elapsed time (s): $(($(date +%s) - start_time))"
  echo "" >> vmem_usage
  top -bn 1 -u $USER | grep -E "wrf.exe|mpiexec" | awk '{ printf("%-8s\n", $5) };' | paste -sd+ | bc >> vmemusage_$currtime
  sleep 1
done


for (( i=0; i<${#jobs[@]}; i++ ))
do
  cd ${run_path}/WRF_${jobs[i]}
  exec 1>> "run.log"
  exec 2>> "run.err"

  if (( ${nslots[i]} > 1 ))
  then
    cat rsl.error.0000 >> run.log
  fi

  echo "The job is about to terminate soon! Killing wrf.exe processes..."
  kill ${pid[i]} &

  echo "job ${jobs[i]} exited with code $?"

  if (( batch == 1 ))
  then
    #save resource usage of job
    currtime=$(date +%d-%m-%Y_%H:%M:%S)
    if [[ $job_scheduler == "sge" ]]
    then
      qstat -j $JOB_ID > resources_${currtime}.info
    elif [[ $job_scheduler == "slurm" ]]
    then
      sacct -j $SLURM_JOB_ID -l -p > resources_${currtime}.info
    fi
    #prepend log to run log
    echo -e "$(cat ${run_path}/logs/$JOB_NAME.out)\n$(cat run.log)" > run.log
    echo -e "$(cat ${run_path}/logs/$JOB_NAME.err)\n$(cat run.err)" > run.err
  fi
done

if (( restart == 1 ))
then
  for (( i=0; i<${#jobs[@]}; i++ ))
  do
    cd ${run_path}/WRF_${jobs[i]}
    exec 1>> "run.log"
    exec 2>> "run.err"
    echo
    echo "Concatenate output from original and restarted run"
    python -c "import misc_tools; misc_tools.concat_restart('$outpath', '${jobs[i]}')"
  done
fi


#echo "trap" $rc
exit ${rc}
